---
output:
  word_document: default
  html_document: default
---

```{r}
library(tidyverse) 
library(GGally)
library(MASS)
library(leaps)
library(caret)
```

```{r}
bike = read_csv("hour.csv")
```

```{r}
bike = bike %>% mutate(season = as_factor(as.character(season))) %>%
mutate(season = fct_recode(season,
"Spring" = "1",
"Summer" = "2",
"Fall" = "3",
"Winter" = "4"))
```

```{r}
bike = bike %>% mutate(yr = as_factor(as.character(yr))) %>%
  mutate(mnth = as_factor(as.character(mnth))) %>%
  mutate(hr = as_factor(as.character(hr)))
```

```{r}
bike = bike %>% mutate(holiday = as_factor(as.character(holiday))) %>%
mutate(holiday = fct_recode(holiday,"NotHoliday" = "0","Holiday" = "1")) 
```

```{r}
bike = bike %>% mutate(workingday = as_factor(as.character(workingday))) %>%
mutate(workingday = fct_recode(workingday,"NotWorkingDay" = "0","WorkingDay" = "1")) 
```

```{r}
bike = bike %>% mutate(weathersit = as_factor(as.character(weathersit))) %>%
mutate(weathersit = fct_recode(weathersit,"NoPrecip" = "1","Misty" = "2", "LightPrecip" = "3", "HeavyPrecip" = "4")) 
```

```{r}
bike = bike %>% mutate(weekday = as_factor(as.character(weekday))) %>%
mutate(weekday = fct_recode(weekday,"Monday" = "1","Tuesday" = "2", "Wednesday" = "3", "Thursday" = "4", "Friday" = "5", "Saturday" = "6", "Sunday" = "0")) 
```

```{r}
set.seed(1234)
train.rows = createDataPartition(y = bike$count, p=0.7, list = FALSE)
train = bike[train.rows,] 
test = bike[-train.rows,]
```

 How many rows of data are in each set (training and testing)?
 // 12167 in training and 5212 in testing.

```{r}
train2 = train %>% dplyr::select("count", "season", "mnth", "hr", "holiday", "weekday", "weathersit", "temp")
```

```{R}
allmod = lm(count ~., train2)
summary(allmod)

emptymod = lm(count ~1, train2)
summary(emptymod)
```

```{r}
forwardmod = stepAIC(emptymod, direction = "forward", scope=list(upper=allmod,lower=emptymod),
                      trace = TRUE)
summary(forwardmod)
```

Adjusted R squared is significantly high, also based on the considerably high number of variables, and the low p value demostrates the quality of the model to be tested for fitting.

```{r}
predict_train = predict(forwardmod, newdata = test)
head(predict_train,6)
```

```{r}
SSE = sum((test$count - predict_train)^2) 
SST = sum((test$count - mean(test$count))^2) 
1 - SSE/SST 
```

The prediction shows an R squated that is just over the R square value of our model, indicating that the model is good to work with unseen data.

Describe how k-fold cross-validation differs from model validation via a training/testing split.
// training / testing split separates a percentage of the number of observations to test in our new model.
k-fold corss-validation creates more than one model (usually 3,5 or 10) in which different portions of the data are separated to use as test.

## Brian Adrino - Module 3 Assignment 1





















